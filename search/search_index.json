{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tabeline Tabeline is a data frame and data grammar library. You write the expressions in strings and supply them to methods on the DataFrame class, like df.filter(\"t <= 24\") . The strings are parsed by Parsita and converted into Polars for execution. Tabeline draws inspiration from dplyr , the data grammar of R's tidyverse. The filter , mutate , group_by , and summarize methods should all feel familiar. But Tabeline is as proper a Python library as can be, using methods instead of pipe operators. Tabeline uses Polars under the hood, but adds a lot of handling of edge cases from Polars, which otherwise result in crashes or behavior that is not type stable. Installation It is recommended to install Tabeline from PyPI using pip . pip install tabeline Motivating example from tabeline import DataFrame # Construct a data frame using clean syntax # from_csv, from_pandas, and from_polars are also available df = DataFrame ( id = [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], t = [ 0 , 6 , 12 , 24 , 0 , 6 , 12 , 24 , 48 ], y = [ 0 , 2 , 3 , 1 , 0 , 4 , 3 , 2 , 1 ], ) # Use data grammar methods and string expressions to define # transformed data frames analysis = ( df . filter ( \"t <= 24\" ) . group_by ( \"id\" ) . summarize ( auc = \"trapz(t, y)\" ) ) print ( analysis ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 auc \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 45.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 63.0 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Data grammar A data grammar is a particular style of data frame library popularized by Hadley Wickham via the dplyr package in R. In a library written as a data grammar, the data frame object has a relatively small number of methods. The parameters of most of these methods are columns names or expressions of column names. The return value of most of these methods is a new data frame. These methods that transform a data frame into another data frame by taking simple inputs are called the \"verbs\" of the data grammar. Each verb does a single simple transformation. By always returning a new data frame, the verbs can be cleanly combined via method chaining. The filter and summarize methods in the above example are two such verbs. A user who wants to do an analysis of a data frame, however basic, is unlikely to find a single function that does exactly what he wants. This is by design. It is not feasible to make a data frame library that has a function for every kind of analysis someone would want. Tabeline expects the user to learn the data grammar so that he can split the analysis into steps than can be performed by verbs. Expressions Tabeline uses strings to encapsulate expressions. The \"t <= 24\" and \"trapz(t, y)\" strings in above example are two such expressions. These strings are parsed and executed. The reason for using strings is that there is no cleaner way to write expressions in Python that need to be evaluated in a different context, namely in the context of the data frame. In R, all functions are effectively macros that can capture any expressions they are given to be executed at a later time. For example, df %>% filter(t <= 24) in dplyr evaluates using the t column in the data frame, not the t variable in the outer scope, if it is even defined. In Python, the closest thing is the lambda . It would be trivial to make an interface that single argument function, which would be passed to the data frame or some modified version of the data frame. For example, df.filter(lambda df: df.t <= 24) . However, anonymous functions have particularly bad syntax in Python, and they work particularly badly in the face of multiple arguments (like would be needed for mutate ). The lambda operator has lower precedence than the commas that separate arguments, so most lambdas need to be surrounded by parentheses.","title":"Home"},{"location":"#tabeline","text":"Tabeline is a data frame and data grammar library. You write the expressions in strings and supply them to methods on the DataFrame class, like df.filter(\"t <= 24\") . The strings are parsed by Parsita and converted into Polars for execution. Tabeline draws inspiration from dplyr , the data grammar of R's tidyverse. The filter , mutate , group_by , and summarize methods should all feel familiar. But Tabeline is as proper a Python library as can be, using methods instead of pipe operators. Tabeline uses Polars under the hood, but adds a lot of handling of edge cases from Polars, which otherwise result in crashes or behavior that is not type stable.","title":"Tabeline"},{"location":"#installation","text":"It is recommended to install Tabeline from PyPI using pip . pip install tabeline","title":"Installation"},{"location":"#motivating-example","text":"from tabeline import DataFrame # Construct a data frame using clean syntax # from_csv, from_pandas, and from_polars are also available df = DataFrame ( id = [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 ], t = [ 0 , 6 , 12 , 24 , 0 , 6 , 12 , 24 , 48 ], y = [ 0 , 2 , 3 , 1 , 0 , 4 , 3 , 2 , 1 ], ) # Use data grammar methods and string expressions to define # transformed data frames analysis = ( df . filter ( \"t <= 24\" ) . group_by ( \"id\" ) . summarize ( auc = \"trapz(t, y)\" ) ) print ( analysis ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 auc \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 45.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 63.0 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Motivating example"},{"location":"#data-grammar","text":"A data grammar is a particular style of data frame library popularized by Hadley Wickham via the dplyr package in R. In a library written as a data grammar, the data frame object has a relatively small number of methods. The parameters of most of these methods are columns names or expressions of column names. The return value of most of these methods is a new data frame. These methods that transform a data frame into another data frame by taking simple inputs are called the \"verbs\" of the data grammar. Each verb does a single simple transformation. By always returning a new data frame, the verbs can be cleanly combined via method chaining. The filter and summarize methods in the above example are two such verbs. A user who wants to do an analysis of a data frame, however basic, is unlikely to find a single function that does exactly what he wants. This is by design. It is not feasible to make a data frame library that has a function for every kind of analysis someone would want. Tabeline expects the user to learn the data grammar so that he can split the analysis into steps than can be performed by verbs.","title":"Data grammar"},{"location":"#expressions","text":"Tabeline uses strings to encapsulate expressions. The \"t <= 24\" and \"trapz(t, y)\" strings in above example are two such expressions. These strings are parsed and executed. The reason for using strings is that there is no cleaner way to write expressions in Python that need to be evaluated in a different context, namely in the context of the data frame. In R, all functions are effectively macros that can capture any expressions they are given to be executed at a later time. For example, df %>% filter(t <= 24) in dplyr evaluates using the t column in the data frame, not the t variable in the outer scope, if it is even defined. In Python, the closest thing is the lambda . It would be trivial to make an interface that single argument function, which would be passed to the data frame or some modified version of the data frame. For example, df.filter(lambda df: df.t <= 24) . However, anonymous functions have particularly bad syntax in Python, and they work particularly badly in the face of multiple arguments (like would be needed for mutate ). The lambda operator has lower precedence than the commas that separate arguments, so most lambdas need to be surrounded by parentheses.","title":"Expressions"},{"location":"contributing/","text":"Contributing Tabeline is free and open source software developed under an MIT license. Development occurs at the GitHub project . Contributions, big and small, are welcome. Bug reports and feature requests may be made directly on the issues tab. To make a pull request, you will need to fork the repo, clone the repo, make the changes, run the tests, push the changes, and open a PR . Cloning the repo To make a local copy of Tabeline, clone the repository with git: git clone https://github.com/drhagen/tabeline.git Installing from source Tabeline uses Poetry as its packaging and dependency manager. In whatever Python environment you prefer, install Poetry and then use Poetry to install Tabeline and its dependencies: pip install poetry poetry install Testing Tabeline uses pytest to run the tests in the tests/ directory. The test command is encapsulated with Nox: poetry run nox -s test test_pandas This will try to test with all compatible Python versions that nox can find. To run the tests with only a particular version, run something like this: poetry run nox -s test-3.9 test_pandas-3.9 It is good to run the tests locally before making a PR, but it is not necessary to have all Python versions run. It is rare for a failure to appear in a single version, and the CI will catch it anyway. Code quality Tabeline uses Black, isort, and Flake8 to ensure a minimum standard of code quality. The code quality commands are encapsulated with Nox: poetry run nox -s black poetry run nox -s isort poetry run nox -s flake8 Generating the docs Tabeline uses MkDocs to generate HTML docs from Markdown. For development purposes, they can be served locally without needing to build them first: poetry run mkdocs serve To deploy the current docs to GitHub Pages, Tabeline uses the MkDocs gh-deploy command that builds the static site on the gh-pages branch, commits, and pushes to the origin: poetry run mkdocs gh-deploy Making a release Bump Increment version in pyproject.toml Commit with message \"Bump version number to X.Y.Z\" Push commit to GitHub Check GitHub Actions to ensure all tests pass Tag Tag commit with \"vX.Y.Z\" Push tag to GitHub Check GitHub Actions for tag Build Clear dist/ Run poetry build Verify that sdist ( .tar.gz ) and bdist ( .whl ) are in dist/ Publish Run poetry publish -r test Check PyPI test server for good upload Run poetry publish Check PyPI for good upload Document Create GitHub release with name \"Tabeline X.Y.Z\" and major changes in body If appropriate, deploy updated docs","title":"Contributing"},{"location":"contributing/#contributing","text":"Tabeline is free and open source software developed under an MIT license. Development occurs at the GitHub project . Contributions, big and small, are welcome. Bug reports and feature requests may be made directly on the issues tab. To make a pull request, you will need to fork the repo, clone the repo, make the changes, run the tests, push the changes, and open a PR .","title":"Contributing"},{"location":"contributing/#cloning-the-repo","text":"To make a local copy of Tabeline, clone the repository with git: git clone https://github.com/drhagen/tabeline.git","title":"Cloning the repo"},{"location":"contributing/#installing-from-source","text":"Tabeline uses Poetry as its packaging and dependency manager. In whatever Python environment you prefer, install Poetry and then use Poetry to install Tabeline and its dependencies: pip install poetry poetry install","title":"Installing from source"},{"location":"contributing/#testing","text":"Tabeline uses pytest to run the tests in the tests/ directory. The test command is encapsulated with Nox: poetry run nox -s test test_pandas This will try to test with all compatible Python versions that nox can find. To run the tests with only a particular version, run something like this: poetry run nox -s test-3.9 test_pandas-3.9 It is good to run the tests locally before making a PR, but it is not necessary to have all Python versions run. It is rare for a failure to appear in a single version, and the CI will catch it anyway.","title":"Testing"},{"location":"contributing/#code-quality","text":"Tabeline uses Black, isort, and Flake8 to ensure a minimum standard of code quality. The code quality commands are encapsulated with Nox: poetry run nox -s black poetry run nox -s isort poetry run nox -s flake8","title":"Code quality"},{"location":"contributing/#generating-the-docs","text":"Tabeline uses MkDocs to generate HTML docs from Markdown. For development purposes, they can be served locally without needing to build them first: poetry run mkdocs serve To deploy the current docs to GitHub Pages, Tabeline uses the MkDocs gh-deploy command that builds the static site on the gh-pages branch, commits, and pushes to the origin: poetry run mkdocs gh-deploy","title":"Generating the docs"},{"location":"contributing/#making-a-release","text":"Bump Increment version in pyproject.toml Commit with message \"Bump version number to X.Y.Z\" Push commit to GitHub Check GitHub Actions to ensure all tests pass Tag Tag commit with \"vX.Y.Z\" Push tag to GitHub Check GitHub Actions for tag Build Clear dist/ Run poetry build Verify that sdist ( .tar.gz ) and bdist ( .whl ) are in dist/ Publish Run poetry publish -r test Check PyPI test server for good upload Run poetry publish Check PyPI for good upload Document Create GitHub release with name \"Tabeline X.Y.Z\" and major changes in body If appropriate, deploy updated docs","title":"Making a release"},{"location":"creation/","text":"Creating a data frame The central class of Tabeline is tabeline.DataFrame . There is little to do with Tabeline other than constructing a DataFrame and invoking methods on it to get a different DataFrame . To create a DataFrame , you can either use the constructor or several static methods on the class. DataFrame The constructor for DataFrame takes an arbitrary number of named arguments. The name of each argument creates a column with the same name. The value of each named argument must be a list, which becomes the values under that column. Naturally, all provided lists must have the same length. from tabeline import DataFrame df = DataFrame ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], ) Note If you poke around in the code, you may notice that the contructor also takes positional arguments. Those are part of the private constructor; don't use them. DataFrame.read_csv Reads a data frame from a CSV file. from pathlib import Path from tabeline import DataFrame df = DataFrame . read_csv ( Path ( \"star_wars.csv\" )) DataFrame.from_pandas Create a tabeline.DataFrame from a pandas.DataFrame . This ignores the index. Use df.reset_index() on the Pandas DataFrame to copy the index to columns first. import pandas as pd from tabeline import DataFrame pandas_df = pd . DataFrame ( dict ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], )) df = DataFrame . from_pandas ( pandas_df ) DataFrame.from_polars Create a tabeline.DataFrame from a polars.DataFrame . Because Tabeline uses Polars internally, this is a simple wrapper. import polars as pl from tabeline import DataFrame polars_df = pl . DataFrame ( dict ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], )) df = DataFrame . from_polars ( polars_df )","title":"Data frame creation"},{"location":"creation/#creating-a-data-frame","text":"The central class of Tabeline is tabeline.DataFrame . There is little to do with Tabeline other than constructing a DataFrame and invoking methods on it to get a different DataFrame . To create a DataFrame , you can either use the constructor or several static methods on the class.","title":"Creating a data frame"},{"location":"creation/#dataframe","text":"The constructor for DataFrame takes an arbitrary number of named arguments. The name of each argument creates a column with the same name. The value of each named argument must be a list, which becomes the values under that column. Naturally, all provided lists must have the same length. from tabeline import DataFrame df = DataFrame ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], ) Note If you poke around in the code, you may notice that the contructor also takes positional arguments. Those are part of the private constructor; don't use them.","title":"DataFrame"},{"location":"creation/#dataframeread_csv","text":"Reads a data frame from a CSV file. from pathlib import Path from tabeline import DataFrame df = DataFrame . read_csv ( Path ( \"star_wars.csv\" ))","title":"DataFrame.read_csv"},{"location":"creation/#dataframefrom_pandas","text":"Create a tabeline.DataFrame from a pandas.DataFrame . This ignores the index. Use df.reset_index() on the Pandas DataFrame to copy the index to columns first. import pandas as pd from tabeline import DataFrame pandas_df = pd . DataFrame ( dict ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], )) df = DataFrame . from_pandas ( pandas_df )","title":"DataFrame.from_pandas"},{"location":"creation/#dataframefrom_polars","text":"Create a tabeline.DataFrame from a polars.DataFrame . Because Tabeline uses Polars internally, this is a simple wrapper. import polars as pl from tabeline import DataFrame polars_df = pl . DataFrame ( dict ( name = [ \"A New Hope\" , \"The Empire Strikes Back\" , \"Return of the Jedi\" ], episode = [ 4 , 5 , 6 ], release_year = [ 1977 , 1980 , 1983 ], )) df = DataFrame . from_polars ( polars_df )","title":"DataFrame.from_polars"},{"location":"summary/","text":"Index This is an index of the main functionality available in Tabeline. Each constructor and verb has a link to more detailed documentation. The expression functions do not yet have detailed documentation, but should be self-explanatory. Creation These are the ways to create a DataFrame from something that is not already a DataFrame DataFrame(**columns) : Construct data frame directly from columns DataFrame.read_csv(filename) : Read data frame from CSV file DataFrame.from_pandas(df) : Convert from Pandas DataFrame DataFrame.from_polars(df) : Convert from Polars DataFrame Verbs Each verb is a method of DataFrame . Column reorganization select : Keep given columns deselect : Drop given columns rename : Rename columns Row removal filter : Keep rows for which predicate is true slice0 : Keep rows given by 0-index slice1 : Keep rows given by 1-index distinct : Drop rows with duplicate values under given columns unique : Drop rows with duplicate values under all columns Row reordering sort : Sort data frame according to given columns cluster : Bring rows together with same values under given columns Column mutation mutate : Create or update columns according to given expressions transmute : Mutate while dropping existing columns Grouping group_by : Create a group level containing given columns ungroup : Drop the last group level Summarizing summarize : Reduce each group to a single row according to given expressions Reshaping spread : Reshape from long format to wide format gather : Reshape from wide format to long format Joining inner_join : Merge data frames, dropping unmatched outer_join : Merge data frames, adding nulls for unmatched left_join : Merge data frames, adding nulls for unmatched on the left data frame Functions These are the operators and functions available in the string expressions. Operators x + y : x plus y or, if strings, x concatenated to y x - y : x minus y x * y : x times y x / y : x divided by y x % y : x mod y x ** y : x to the power of y Numeric to numeric broadcast The functions in this section mathematical operations on numbers. If these functions receive scalar inputs, they return a scalar. If they receive any array inputs, any scalars are interpreted as constant vectors and an array is returned. abs(x) : Absolute value of x sqrt(x) : Square root of x log(x) : Natural logarithm of x log2(x) : Base-2 logarithm of x log10(x) : Base-10 logarithm of x exp(x) : Euler's number e to the power of x pow(x, y) : x to the power of y sin(x) : Sine of x cos(x) : Cosine of x tan(x) : Tangent of x floor(x) : x rounded down to the nearest integer ceil(x) : x rounded up to the nearest integer Numeric to boolean broadcast is_nan : True if numeric value is a floating point NaN Numeric to numeric reduction The functions in this section consume an entire column of numbers and to produce a scalar number. std(x) : Population standard deviation of x var(x) : Population variacne of x max(x) : Maximum of x min(x) : Minimum of x sum(x) : Sum of x mean(x) : Mean of x median(x) : Median of x quantile(x, quantile) : The quantile of x obtained via linear interpolation quantile must be a float not an expression trapz(x, y) : Numerically integrate y over x using the trapezoidal rule Boolean to boolean reduction The functions in this section consume an entire column of booleans and to produce a scalar boolean. any(x) : True if any of x are true all(x) : True is all of x are true Any to any reduction The functions in this section consume an entire column of anything and to produce a scalar of that type. first(x) : The first value of x last(x) : The last value of x","title":"Index"},{"location":"summary/#index","text":"This is an index of the main functionality available in Tabeline. Each constructor and verb has a link to more detailed documentation. The expression functions do not yet have detailed documentation, but should be self-explanatory.","title":"Index"},{"location":"summary/#creation","text":"These are the ways to create a DataFrame from something that is not already a DataFrame DataFrame(**columns) : Construct data frame directly from columns DataFrame.read_csv(filename) : Read data frame from CSV file DataFrame.from_pandas(df) : Convert from Pandas DataFrame DataFrame.from_polars(df) : Convert from Polars DataFrame","title":"Creation"},{"location":"summary/#verbs","text":"Each verb is a method of DataFrame .","title":"Verbs"},{"location":"summary/#column-reorganization","text":"select : Keep given columns deselect : Drop given columns rename : Rename columns","title":"Column reorganization"},{"location":"summary/#row-removal","text":"filter : Keep rows for which predicate is true slice0 : Keep rows given by 0-index slice1 : Keep rows given by 1-index distinct : Drop rows with duplicate values under given columns unique : Drop rows with duplicate values under all columns","title":"Row removal"},{"location":"summary/#row-reordering","text":"sort : Sort data frame according to given columns cluster : Bring rows together with same values under given columns","title":"Row reordering"},{"location":"summary/#column-mutation","text":"mutate : Create or update columns according to given expressions transmute : Mutate while dropping existing columns","title":"Column mutation"},{"location":"summary/#grouping","text":"group_by : Create a group level containing given columns ungroup : Drop the last group level","title":"Grouping"},{"location":"summary/#summarizing","text":"summarize : Reduce each group to a single row according to given expressions","title":"Summarizing"},{"location":"summary/#reshaping","text":"spread : Reshape from long format to wide format gather : Reshape from wide format to long format","title":"Reshaping"},{"location":"summary/#joining","text":"inner_join : Merge data frames, dropping unmatched outer_join : Merge data frames, adding nulls for unmatched left_join : Merge data frames, adding nulls for unmatched on the left data frame","title":"Joining"},{"location":"summary/#functions","text":"These are the operators and functions available in the string expressions.","title":"Functions"},{"location":"summary/#operators","text":"x + y : x plus y or, if strings, x concatenated to y x - y : x minus y x * y : x times y x / y : x divided by y x % y : x mod y x ** y : x to the power of y","title":"Operators"},{"location":"summary/#numeric-to-numeric-broadcast","text":"The functions in this section mathematical operations on numbers. If these functions receive scalar inputs, they return a scalar. If they receive any array inputs, any scalars are interpreted as constant vectors and an array is returned. abs(x) : Absolute value of x sqrt(x) : Square root of x log(x) : Natural logarithm of x log2(x) : Base-2 logarithm of x log10(x) : Base-10 logarithm of x exp(x) : Euler's number e to the power of x pow(x, y) : x to the power of y sin(x) : Sine of x cos(x) : Cosine of x tan(x) : Tangent of x floor(x) : x rounded down to the nearest integer ceil(x) : x rounded up to the nearest integer","title":"Numeric to numeric broadcast"},{"location":"summary/#numeric-to-boolean-broadcast","text":"is_nan : True if numeric value is a floating point NaN","title":"Numeric to boolean broadcast"},{"location":"summary/#numeric-to-numeric-reduction","text":"The functions in this section consume an entire column of numbers and to produce a scalar number. std(x) : Population standard deviation of x var(x) : Population variacne of x max(x) : Maximum of x min(x) : Minimum of x sum(x) : Sum of x mean(x) : Mean of x median(x) : Median of x quantile(x, quantile) : The quantile of x obtained via linear interpolation quantile must be a float not an expression trapz(x, y) : Numerically integrate y over x using the trapezoidal rule","title":"Numeric to numeric reduction"},{"location":"summary/#boolean-to-boolean-reduction","text":"The functions in this section consume an entire column of booleans and to produce a scalar boolean. any(x) : True if any of x are true all(x) : True is all of x are true","title":"Boolean to boolean reduction"},{"location":"summary/#any-to-any-reduction","text":"The functions in this section consume an entire column of anything and to produce a scalar of that type. first(x) : The first value of x last(x) : The last value of x","title":"Any to any reduction"},{"location":"verbs/filter/","text":"Row dropping The filter , slice0 , slice1 , distinct , and unique verbs change which rows are present. The relative order of the rows is unchanged. filter Keep the rows for which a given predicate evaluates to true. filter takes a single expression, which in the context of the data frame, must evaluate to a boolean column. All rows with a corresponding false value are dropped. from tabeline import DataFrame df = DataFrame ( name = [ \"Alice\" , \"Bob\" , \"Carole\" , \"Mallory\" ], age = [ 28 , 55 , 55 , 18 ], ) df . filter ( \"age == max(age)\" ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 age \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 Bob \u2506 55 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 Carole \u2506 55 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518 slice0 Keep only the rows whose 0-based index is listed, and in the order listed. from tabeline import DataFrame df = DataFrame ( id = [ 1 , 2 , 3 , 4 ], character = [ \"a\" , \"b\" , \"c\" , \"d\" ], ) df . slice0 ([ 2 , 1 ]) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 character \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 3 \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 b \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 slice1 Keep only the rows whose 1-based index is listed, and in the order listed. This is identical to slice0 except for the interpretation of the index. from tabeline import DataFrame df = DataFrame ( id = [ 1 , 2 , 3 , 4 ], character = [ \"a\" , \"b\" , \"c\" , \"d\" ], ) df . slice1 ([ 2 , 1 ]) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 character \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 2 \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 a \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Filtering"},{"location":"verbs/filter/#row-dropping","text":"The filter , slice0 , slice1 , distinct , and unique verbs change which rows are present. The relative order of the rows is unchanged.","title":"Row dropping"},{"location":"verbs/filter/#filter","text":"Keep the rows for which a given predicate evaluates to true. filter takes a single expression, which in the context of the data frame, must evaluate to a boolean column. All rows with a corresponding false value are dropped. from tabeline import DataFrame df = DataFrame ( name = [ \"Alice\" , \"Bob\" , \"Carole\" , \"Mallory\" ], age = [ 28 , 55 , 55 , 18 ], ) df . filter ( \"age == max(age)\" ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 age \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 Bob \u2506 55 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 Carole \u2506 55 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518","title":"filter"},{"location":"verbs/filter/#slice0","text":"Keep only the rows whose 0-based index is listed, and in the order listed. from tabeline import DataFrame df = DataFrame ( id = [ 1 , 2 , 3 , 4 ], character = [ \"a\" , \"b\" , \"c\" , \"d\" ], ) df . slice0 ([ 2 , 1 ]) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 character \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 3 \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 b \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"slice0"},{"location":"verbs/filter/#slice1","text":"Keep only the rows whose 1-based index is listed, and in the order listed. This is identical to slice0 except for the interpretation of the index. from tabeline import DataFrame df = DataFrame ( id = [ 1 , 2 , 3 , 4 ], character = [ \"a\" , \"b\" , \"c\" , \"d\" ], ) df . slice1 ([ 2 , 1 ]) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 character \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 2 \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 a \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"slice1"},{"location":"verbs/group_by/","text":"Grouping group_by is not so much a verb as it is a preposition. group_by does not change the contents or orders of any rows or columns, but it changes the context of subsequent verbs. All rows which have the same values in all group_by columns are members of the same subframe. Subsequent verbs act as if they are applied each subframe individually. So in filter or mutate , an expression containing max or mean will apply only to the rows in each subframe. Tabeline is different from all popular data grammar libraries in how it handles groups. An instance of DataFrame has group levels. Each invocation of group_by adds one group level, which can contain any number of columns names by which to group. The flattened list of group names from all levels can be accessed via the group_names property. group_by Add a set of column names as a new group level. The column names must exist, and they must not be previously grouped. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . mutate ( mean = \"mean(x)\" ) # group levels: [id] # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2506 mean \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1 \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 a \u2506 2 \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3 \u2506 3.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 4 \u2506 3.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 ungroup Drop the last group level. The existence of group levels causes this to behave differently from dplyr. This does not remove all group names, only those present in the last group level. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . mutate ( mean = \"mean(x)\" ) # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2506 mean \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 a \u2506 2 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 4 \u2506 2.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Grouping"},{"location":"verbs/group_by/#grouping","text":"group_by is not so much a verb as it is a preposition. group_by does not change the contents or orders of any rows or columns, but it changes the context of subsequent verbs. All rows which have the same values in all group_by columns are members of the same subframe. Subsequent verbs act as if they are applied each subframe individually. So in filter or mutate , an expression containing max or mean will apply only to the rows in each subframe. Tabeline is different from all popular data grammar libraries in how it handles groups. An instance of DataFrame has group levels. Each invocation of group_by adds one group level, which can contain any number of columns names by which to group. The flattened list of group names from all levels can be accessed via the group_names property.","title":"Grouping"},{"location":"verbs/group_by/#group_by","text":"Add a set of column names as a new group level. The column names must exist, and they must not be previously grouped. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . mutate ( mean = \"mean(x)\" ) # group levels: [id] # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2506 mean \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1 \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 a \u2506 2 \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3 \u2506 3.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 4 \u2506 3.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"group_by"},{"location":"verbs/group_by/#ungroup","text":"Drop the last group level. The existence of group levels causes this to behave differently from dplyr. This does not remove all group names, only those present in the last group level. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . mutate ( mean = \"mean(x)\" ) # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2506 mean \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 a \u2506 2 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3 \u2506 2.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 4 \u2506 2.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"ungroup"},{"location":"verbs/join/","text":"Joining The inner_join , outer_join , and left_join verbs perform the classic table join operations. inner_join This method performs the classic inner join operation. Rows on either side that are missing a corresponding row on the other side are dropped. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . inner_join ( df2 ) # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518 outer_join This method performs the classic outer join (or full join) operation. Rows on either side that are missing a corresponding row on the other side are kept, filling the other side with nulls. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . outer_join ( df2 ) # shape: (6, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 -1 \u2506 null \u2506 z \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 4 \u2506 e \u2506 null \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 left_join This method performs the classic left join operation. Rows on the left side that are missing a corresponding row on the right side are kept, filling the right side with nulls. Rows on the right side that are missing a corresponding row on the left side are dropped. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . left_join ( df2 ) # shape: (5, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 4 \u2506 e \u2506 null \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Joining"},{"location":"verbs/join/#joining","text":"The inner_join , outer_join , and left_join verbs perform the classic table join operations.","title":"Joining"},{"location":"verbs/join/#inner_join","text":"This method performs the classic inner join operation. Rows on either side that are missing a corresponding row on the other side are dropped. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . inner_join ( df2 ) # shape: (4, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518","title":"inner_join"},{"location":"verbs/join/#outer_join","text":"This method performs the classic outer join (or full join) operation. Rows on either side that are missing a corresponding row on the other side are kept, filling the other side with nulls. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . outer_join ( df2 ) # shape: (6, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 -1 \u2506 null \u2506 z \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 4 \u2506 e \u2506 null \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"outer_join"},{"location":"verbs/join/#left_join","text":"This method performs the classic left join operation. Rows on the left side that are missing a corresponding row on the right side are kept, filling the right side with nulls. Rows on the right side that are missing a corresponding row on the left side are dropped. Rows on either side that have multiple matches on the other side are duplicated. from tabeline import DataFrame df1 = DataFrame ( x = [ 0 , 1 , 2 , 3 , 4 ], y = [ \"a\" , \"b\" , \"c\" , \"d\" , \"e\" ]) df2 = DataFrame ( x = [ 3 , 2 , - 1 , 1 , 0 ], z = [ \"a\" , \"b\" , \"z\" , \"c\" , \"d\" ]) df1 . left_join ( df2 ) # shape: (5, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 x \u2506 y \u2506 z \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 str \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 0 \u2506 a \u2506 d \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 b \u2506 c \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 c \u2506 b \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 3 \u2506 d \u2506 a \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 4 \u2506 e \u2506 null \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"left_join"},{"location":"verbs/mutate/","text":"New column creating The mutate and transmute verbs create new columns based on expressions of existing columns. The number of rows is unchanged. mutate Create new columns or redefine existing columns. This takes an arbitrary number of named arguments. The name of each argument is the name of a column. The value of the argument is an expression that provides a definition for that column. If the column name already exists, that column will be replaced by the evaluation of the new definition. If the column name does not already exist, the new column will be appended to the existing columns. from tabeline import DataFrame df = DataFrame ( name = [ \"wide\" , \"tall\" , \"square\" ], width = [ 5 , 2 , 3 ], height = [ 1 , 4 , 3 ], ) df . mutate ( area = \"width * height\" ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 width \u2506 height \u2506 area \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 i64 \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 wide \u2506 5 \u2506 1 \u2506 5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 tall \u2506 2 \u2506 4 \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 square \u2506 3 \u2506 3 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 transmute Just like mutate except the existing columns are not kept. This is identical to mutate followed by select on the newly defined columns. from tabeline import DataFrame df = DataFrame ( name = [ \"wide\" , \"tall\" , \"square\" ], width = [ 5 , 2 , 3 ], height = [ 1 , 4 , 3 ], ) df . transmute ( name = \"name\" , area = \"width * height\" ) # shape: (3, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 area \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 wide \u2506 5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 tall \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 square \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Mutation"},{"location":"verbs/mutate/#new-column-creating","text":"The mutate and transmute verbs create new columns based on expressions of existing columns. The number of rows is unchanged.","title":"New column creating"},{"location":"verbs/mutate/#mutate","text":"Create new columns or redefine existing columns. This takes an arbitrary number of named arguments. The name of each argument is the name of a column. The value of the argument is an expression that provides a definition for that column. If the column name already exists, that column will be replaced by the evaluation of the new definition. If the column name does not already exist, the new column will be appended to the existing columns. from tabeline import DataFrame df = DataFrame ( name = [ \"wide\" , \"tall\" , \"square\" ], width = [ 5 , 2 , 3 ], height = [ 1 , 4 , 3 ], ) df . mutate ( area = \"width * height\" ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 width \u2506 height \u2506 area \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 i64 \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 wide \u2506 5 \u2506 1 \u2506 5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 tall \u2506 2 \u2506 4 \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 square \u2506 3 \u2506 3 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"mutate"},{"location":"verbs/mutate/#transmute","text":"Just like mutate except the existing columns are not kept. This is identical to mutate followed by select on the newly defined columns. from tabeline import DataFrame df = DataFrame ( name = [ \"wide\" , \"tall\" , \"square\" ], width = [ 5 , 2 , 3 ], height = [ 1 , 4 , 3 ], ) df . transmute ( name = \"name\" , area = \"width * height\" ) # shape: (3, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 name \u2506 area \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 wide \u2506 5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 tall \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 square \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"transmute"},{"location":"verbs/select/","text":"Column dropping and reordering The select , deselect , and rename verbs change which columns are present in the data frame, their order, and what names they have. The content of the columns is unchanged. select Keep only the columns whose names are listed, in the order they are listed. from tabeline import DataFrame df = DataFrame ( study = [ 1 , 2 ], location = [ \"USA\" , \"USA\" ], cost = [ 3254 , 11843 ], success = [ True , False ], ) df . select ( \"study\" , \"success\" , \"cost\" ) # shape: (2, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 study \u2506 success \u2506 cost \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 bool \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 true \u2506 3254 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 false \u2506 11843 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 deselect Drop the columns whose names are listed. from tabeline import DataFrame df = DataFrame ( study = [ 1 , 2 ], location = [ \"USA\" , \"USA\" ], cost = [ 3254 , 11843 ], success = [ True , False ], ) df . deselect ( \"location\" ) # shape: (2, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 study \u2506 cost \u2506 success \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 i64 \u2506 bool \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 3254 \u2506 true \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 11843 \u2506 false \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 rename Change the name of some columns, keeping their original order unchanged. This takes named arguments, where the key is the new name and the value is the old name. In this, Tabeline is like dyplr rename rather than Polars rename , which flips the order of the new and old names. The renaming happens simultaneously, allowing column names to be swapped. from tabeline import DataFrame df = DataFrame ( name = [ 1 , 2 ], full_name = [ \"Alice\" , \"Bob\" ], age = [ 27 , 55 ], authorized = [ True , True ], ) df . rename ( name = \"full_name\" , id = \"name\" ) # shape: (2, 4) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 name \u2506 age \u2506 authorized \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 i64 \u2506 bool \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 Alice \u2506 27 \u2506 true \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 Bob \u2506 55 \u2506 true \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Reorganizing"},{"location":"verbs/select/#column-dropping-and-reordering","text":"The select , deselect , and rename verbs change which columns are present in the data frame, their order, and what names they have. The content of the columns is unchanged.","title":"Column dropping and reordering"},{"location":"verbs/select/#select","text":"Keep only the columns whose names are listed, in the order they are listed. from tabeline import DataFrame df = DataFrame ( study = [ 1 , 2 ], location = [ \"USA\" , \"USA\" ], cost = [ 3254 , 11843 ], success = [ True , False ], ) df . select ( \"study\" , \"success\" , \"cost\" ) # shape: (2, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 study \u2506 success \u2506 cost \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 bool \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 true \u2506 3254 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 false \u2506 11843 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"select"},{"location":"verbs/select/#deselect","text":"Drop the columns whose names are listed. from tabeline import DataFrame df = DataFrame ( study = [ 1 , 2 ], location = [ \"USA\" , \"USA\" ], cost = [ 3254 , 11843 ], success = [ True , False ], ) df . deselect ( \"location\" ) # shape: (2, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 study \u2506 cost \u2506 success \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 i64 \u2506 bool \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 3254 \u2506 true \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 11843 \u2506 false \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"deselect"},{"location":"verbs/select/#rename","text":"Change the name of some columns, keeping their original order unchanged. This takes named arguments, where the key is the new name and the value is the old name. In this, Tabeline is like dyplr rename rather than Polars rename , which flips the order of the new and old names. The renaming happens simultaneously, allowing column names to be swapped. from tabeline import DataFrame df = DataFrame ( name = [ 1 , 2 ], full_name = [ \"Alice\" , \"Bob\" ], age = [ 27 , 55 ], authorized = [ True , True ], ) df . rename ( name = \"full_name\" , id = \"name\" ) # shape: (2, 4) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 name \u2506 age \u2506 authorized \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 str \u2506 i64 \u2506 bool \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 Alice \u2506 27 \u2506 true \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 Bob \u2506 55 \u2506 true \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"rename"},{"location":"verbs/sort/","text":"Row reordering The sort and cluster verbs change the order of rows. The individual rows are unchanged. sort Sort rows according to the given column names. The data frame is sorted by the first column name using subsequent columns to break any ties. from tabeline import DataFrame df = DataFrame ( patient_id = [ 2 , 1 , 2 , 1 , 2 , 1 ], t = [ 0.0 , 0.0 , 6.0 , 6.0 , 24.0 , 24.0 ], measurement = [ 6.0 , 5.5 , 4.2 , 4.0 , 3.1 , 3.0 ], ) df . sort ( \"patient_id\" , \"t\" ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 patient_id \u2506 t \u2506 measurement \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 0.0 \u2506 5.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 6.0 \u2506 4.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 24.0 \u2506 3.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 0.0 \u2506 6.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 6.0 \u2506 4.2 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 24.0 \u2506 3.1 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 cluster Bring together all the rows with the same value under the given columns. A side effect of sort is that all rows with the same key value under some given columns are brought together. If you want this clustering, without the sorting, cluster will bring all the rows with a given key together, but retain the order of first instance of that key. from tabeline import DataFrame df = DataFrame ( patient_id = [ 2 , 1 , 2 , 1 , 2 , 1 ], t = [ 0.0 , 0.0 , 6.0 , 6.0 , 24.0 , 24.0 ], measurement = [ 6.0 , 5.5 , 4.2 , 4.0 , 3.1 , 3.0 ], ) df . cluster ( \"patient_id\" ) shape : ( 6 , 3 ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 patient_id \u2506 t \u2506 measurement \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 2 \u2506 0.0 \u2506 6.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 6.0 \u2506 4.2 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 24.0 \u2506 3.1 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 0.0 \u2506 5.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 6.0 \u2506 4.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 24.0 \u2506 3.0 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Sorting"},{"location":"verbs/sort/#row-reordering","text":"The sort and cluster verbs change the order of rows. The individual rows are unchanged.","title":"Row reordering"},{"location":"verbs/sort/#sort","text":"Sort rows according to the given column names. The data frame is sorted by the first column name using subsequent columns to break any ties. from tabeline import DataFrame df = DataFrame ( patient_id = [ 2 , 1 , 2 , 1 , 2 , 1 ], t = [ 0.0 , 0.0 , 6.0 , 6.0 , 24.0 , 24.0 ], measurement = [ 6.0 , 5.5 , 4.2 , 4.0 , 3.1 , 3.0 ], ) df . sort ( \"patient_id\" , \"t\" ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 patient_id \u2506 t \u2506 measurement \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 1 \u2506 0.0 \u2506 5.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 6.0 \u2506 4.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 24.0 \u2506 3.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 0.0 \u2506 6.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 6.0 \u2506 4.2 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 24.0 \u2506 3.1 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"sort"},{"location":"verbs/sort/#cluster","text":"Bring together all the rows with the same value under the given columns. A side effect of sort is that all rows with the same key value under some given columns are brought together. If you want this clustering, without the sorting, cluster will bring all the rows with a given key together, but retain the order of first instance of that key. from tabeline import DataFrame df = DataFrame ( patient_id = [ 2 , 1 , 2 , 1 , 2 , 1 ], t = [ 0.0 , 0.0 , 6.0 , 6.0 , 24.0 , 24.0 ], measurement = [ 6.0 , 5.5 , 4.2 , 4.0 , 3.1 , 3.0 ], ) df . cluster ( \"patient_id\" ) shape : ( 6 , 3 ) # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 patient_id \u2506 t \u2506 measurement \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 i64 \u2506 f64 \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 2 \u2506 0.0 \u2506 6.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 6.0 \u2506 4.2 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 2 \u2506 24.0 \u2506 3.1 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 0.0 \u2506 5.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 6.0 \u2506 4.0 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 1 \u2506 24.0 \u2506 3.0 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"cluster"},{"location":"verbs/spread/","text":"Pivoting The spread and gather verbs reshape a data frame between long format and wide format of data representation. spread Turn a long data frame into a wide data frame. This operation takes the names of two columns, a key column and a value column. Every value in the key column becomes a column name and every value in the value column becomes a value under its respective column. spread is a reduction verb. As such, it drops the last group level, and it cannot be applied to data frames with no group levels. from tabeline import DataFrame df = DataFrame ( grades = [ 0 , 0 , 1 , 1 , 2 , 2 ], sex = [ \"M\" , \"F\" , \"M\" , \"F\" , \"M\" , \"F\" ], count = [ 8 , 9 , 9 , 10 , 6 , 9 ] ) df . group_by ( \"sex\" ) . spread ( \"grades\" , \"count\" ) # shape: (2, 4) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 sex \u2506 0 \u2506 1 \u2506 2 \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 i64 \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 M \u2506 8 \u2506 9 \u2506 6 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 9 \u2506 10 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518 gather Turn a wide data frame into a long data frame. This operation takes the name of a key column that not exist, the name of a value column that does not exist, and an arbitrary number of existing column names. Each value under the existing columns is converted to a value under the new value column, with the name of the column put next to it under the key column. gather adds one group level containing the key column name. from tabeline import DataFrame df = DataFrame . from_dict ({ \"sex\" : [ \"M\" , \"F\" ], \"0\" : [ 8 , 9 ], \"1\" : [ 9 , 10 ], \"2\" : [ 6 , 9 ]}, ) df . gather ( \"grades\" , \"count\" , \"0\" , \"1\" , \"2\" ) # group levels: [grades] # shape: (6, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 sex \u2506 grades \u2506 count \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 M \u2506 0 \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 0 \u2506 9 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 M \u2506 1 \u2506 9 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 1 \u2506 10 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 M \u2506 2 \u2506 6 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 2 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Reshaping"},{"location":"verbs/spread/#pivoting","text":"The spread and gather verbs reshape a data frame between long format and wide format of data representation.","title":"Pivoting"},{"location":"verbs/spread/#spread","text":"Turn a long data frame into a wide data frame. This operation takes the names of two columns, a key column and a value column. Every value in the key column becomes a column name and every value in the value column becomes a value under its respective column. spread is a reduction verb. As such, it drops the last group level, and it cannot be applied to data frames with no group levels. from tabeline import DataFrame df = DataFrame ( grades = [ 0 , 0 , 1 , 1 , 2 , 2 ], sex = [ \"M\" , \"F\" , \"M\" , \"F\" , \"M\" , \"F\" ], count = [ 8 , 9 , 9 , 10 , 6 , 9 ] ) df . group_by ( \"sex\" ) . spread ( \"grades\" , \"count\" ) # shape: (2, 4) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 sex \u2506 0 \u2506 1 \u2506 2 \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 i64 \u2506 i64 \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 M \u2506 8 \u2506 9 \u2506 6 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 9 \u2506 10 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518","title":"spread"},{"location":"verbs/spread/#gather","text":"Turn a wide data frame into a long data frame. This operation takes the name of a key column that not exist, the name of a value column that does not exist, and an arbitrary number of existing column names. Each value under the existing columns is converted to a value under the new value column, with the name of the column put next to it under the key column. gather adds one group level containing the key column name. from tabeline import DataFrame df = DataFrame . from_dict ({ \"sex\" : [ \"M\" , \"F\" ], \"0\" : [ 8 , 9 ], \"1\" : [ 9 , 10 ], \"2\" : [ 6 , 9 ]}, ) df . gather ( \"grades\" , \"count\" , \"0\" , \"1\" , \"2\" ) # group levels: [grades] # shape: (6, 3) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 sex \u2506 grades \u2506 count \u2502 # \u2502 --- \u2506 --- \u2506 --- \u2502 # \u2502 str \u2506 str \u2506 i64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 M \u2506 0 \u2506 8 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 0 \u2506 9 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 M \u2506 1 \u2506 9 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 1 \u2506 10 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 M \u2506 2 \u2506 6 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 F \u2506 2 \u2506 9 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"gather"},{"location":"verbs/summarize/","text":"Summarization summarize Reduce each subframe to a single row. This operation can only be applied to a data frame with at least one group level. The result has one column for each group column name and one column for each named argument. The name of the argument becomes the column name and the value of the argument must be an expression that evaluates to a scalar. That scalar will be the value of the cell for each summarized subframe. The last group level is dropped. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . summarize ( x = \"mean(x)\" ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518","title":"Summarizing"},{"location":"verbs/summarize/#summarization","text":"","title":"Summarization"},{"location":"verbs/summarize/#summarize","text":"Reduce each subframe to a single row. This operation can only be applied to a data frame with at least one group level. The result has one column for each group column name and one column for each named argument. The name of the argument becomes the column name and the value of the argument must be an expression that evaluates to a scalar. That scalar will be the value of the cell for each summarized subframe. The last group level is dropped. from tabeline import DataFrame df = DataFrame ( id = [ \"a\" , \"a\" , \"b\" , \"b\" ], x = [ 1 , 2 , 3 , 4 ], ) df . group_by ( \"id\" ) . summarize ( x = \"mean(x)\" ) # shape: (2, 2) # \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510 # \u2502 id \u2506 x \u2502 # \u2502 --- \u2506 --- \u2502 # \u2502 str \u2506 f64 \u2502 # \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561 # \u2502 a \u2506 1.5 \u2502 # \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524 # \u2502 b \u2506 3.5 \u2502 # \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518","title":"summarize"}]}