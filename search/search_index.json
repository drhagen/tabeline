{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tabeline","text":"<p>Tabeline is a data frame and data grammar library. You write the expressions in strings and supply them to methods on the <code>DataFrame</code> class, like <code>df.filter(\"t &lt;= 24\")</code>. The  strings are parsed by Parsita and converted into Polars for execution.</p> <p>Tabeline draws inspiration from dplyr, the data grammar of R's tidyverse. The <code>filter</code>, <code>mutate</code>, <code>group_by</code>, and <code>summarize</code> methods should all feel familiar. But Tabeline is as proper a Python library as can be, using methods instead of pipe operators.</p> <p>Tabeline uses Polars under the hood, but adds a lot of handling of edge cases from Polars, which otherwise result in crashes or behavior that is not type stable.</p>"},{"location":"#installation","title":"Installation","text":"<p>It is recommended to install Tabeline from PyPI using <code>pip</code>.</p> <pre><code>pip install tabeline\n</code></pre>"},{"location":"#motivating-example","title":"Motivating example","text":"<pre><code>from tabeline import DataFrame\n\n# Construct a data frame using clean syntax\n# from_csv, from_pandas, and from_polars are also available\ndf = DataFrame(\n    id=[0, 0, 0, 0, 1, 1, 1, 1, 1],\n    t=[0, 6, 12, 24, 0, 6, 12, 24, 48],\n    y=[0, 2, 3, 1, 0, 4, 3, 2, 1],\n)\n\n# Use data grammar methods and string expressions to define\n# transformed data frames\nanalysis = (\n    df\n    .filter(\"t &lt;= 24\")\n    .group_by(\"id\")\n    .summarize(auc=\"trapz(t, y)\")\n)\n\nprint(analysis)\n# shape: (2, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 auc  \u2502\n# \u2502 --- \u2506 ---  \u2502\n# \u2502 i64 \u2506 f64  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 0   \u2506 45.0 \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1   \u2506 63.0 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#data-grammar","title":"Data grammar","text":"<p>A data grammar is a particular style of data frame library popularized by Hadley Wickham via the dplyr package in R. In a library written as a data grammar, the data frame object has a relatively small number of methods. The parameters of most of these methods are columns names or expressions of column names. The return value of most of these methods is a new data frame. These methods that transform a data frame into another data frame by taking simple inputs are called the \"verbs\" of the data grammar. Each verb does a single simple transformation. By always returning a new data frame, the verbs can be cleanly combined via method chaining. The <code>filter</code> and <code>summarize</code> methods in the above example are two such verbs.</p> <p>Users who want to do an analysis of a data frame, however basic, are unlikely to find a single function that does exactly what they want. This is by design. It is not feasible to make a data frame library that has a function for every kind of analysis someone would want. Tabeline expects users to learn the data grammar so that they can split the analysis into steps than can be performed by verbs.</p>"},{"location":"#expressions","title":"Expressions","text":"<p>Tabeline uses strings to encapsulate expressions. The <code>\"t &lt;= 24\"</code> and <code>\"trapz(t, y)\"</code> strings in above example are two such expressions. These strings are parsed and executed. The reason for using strings is that there is no cleaner way to write expressions in Python that need to be evaluated in a different context, namely in the context of the data frame.</p> <p>In R, all functions are effectively macros that can capture any expressions they are given to be executed at a later time. For example, <code>df %&gt;% filter(t &lt;= 24)</code> in dplyr evaluates using the <code>t</code> column in the data frame, not the <code>t</code> variable in the outer scope, if it is even defined.</p> <p>In Python, the closest thing is the <code>lambda</code>. It would be trivial to make an interface that took a single argument function, which would be passed the data frame or some modified version of the data frame. For example, <code>df.filter(lambda df: df.t &lt;= 24)</code>. However, anonymous functions have particularly bad syntax in Python, and they work particularly badly in the face of multiple arguments (like would be needed for <code>mutate</code>). The <code>lambda</code> operator has lower precedence than the commas that separate arguments, so most lambdas need to be surrounded by parentheses.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Tabeline is free and open source software developed under an MIT license. Development occurs at the GitHub project. Contributions, big and small, are welcome.</p> <p>Bug reports and feature requests may be made directly on the issues tab.</p> <p>To make a pull request, you will need to fork the repo, clone the repo, make the changes, run the tests, push the changes, and open a PR.</p>"},{"location":"contributing/#cloning-the-repo","title":"Cloning the repo","text":"<p>To make a local copy of Tabeline, clone the repository with git:</p> <pre><code>git clone https://github.com/drhagen/tabeline.git\n</code></pre>"},{"location":"contributing/#installing-from-source","title":"Installing from source","text":"<p>Tabeline uses uv as its packaging and dependency manager. In whatever Python environment you prefer, install uv and then use uv to install Tabeline and its dependencies:</p> <pre><code>pip install uv\nuv sync\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Tabeline uses pytest to run the tests in the <code>tests/</code> directory. The test command is encapsulated with Nox:</p> <pre><code>uv run nox -s test test_polars test_pandas\n</code></pre> <p>This will try to test with all compatible Python versions that <code>nox</code> can find. To run the tests with only a particular version, run something like this:</p> <pre><code>uv run nox -s test-3.13 test_pandas-3.13\n</code></pre> <p>It is good to run the tests locally before making a PR, but it is not necessary to have all Python versions run. It is rare for a failure to appear in a single version, and the CI will catch it anyway.</p>"},{"location":"contributing/#code-quality","title":"Code quality","text":"<p>Tabeline uses Ruff to ensure a minimum standard of code quality. The code quality commands are encapsulated with Nox:</p> <pre><code>uv run nox -s lint\n</code></pre>"},{"location":"contributing/#generating-the-docs","title":"Generating the docs","text":"<p>Tabeline uses MkDocs to generate HTML docs from Markdown. For development purposes, they can be served locally without needing to build them first:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>To deploy the current docs to GitHub Pages, Tabeline uses the MkDocs <code>gh-deploy</code> command that builds the static site on the <code>gh-pages</code> branch, commits, and pushes to the origin:</p> <pre><code>uv run mkdocs gh-deploy\n</code></pre>"},{"location":"contributing/#making-a-release","title":"Making a release","text":"<ol> <li>Bump<ol> <li>Increment version in <code>Cargo.toml</code></li> <li>Run <code>cargo check</code> to update <code>Cargo.lock</code></li> <li>Commit with message \"Bump version number to X.Y.Z\"</li> <li>Push commit to GitHub</li> <li>Check CI to ensure all tests pass</li> </ol> </li> <li>Tag<ol> <li>Tag commit with \"vX.Y.Z\"</li> <li>Push tag to GitHub</li> <li>Wait for build to finish</li> <li>Check PyPI for good upload</li> </ol> </li> <li>Document<ol> <li>Create GitHub release with name \"Tabeline X.Y.Z\" and major changes in body</li> <li>If appropriate, deploy updated docs</li> </ol> </li> </ol>"},{"location":"creation/","title":"Creating a data frame","text":"<p>The central class of Tabeline is <code>tabeline.DataFrame</code>. There is little to do with Tabeline other than constructing a <code>DataFrame</code> and invoking methods on it to get a different <code>DataFrame</code>.</p> <p>To create a <code>DataFrame</code>, you can either use the constructor or several static methods on the class.</p>"},{"location":"creation/#dataframe","title":"<code>DataFrame</code>","text":"<p>The constructor for <code>DataFrame</code> takes an arbitrary number of named arguments. The name of each argument creates a column with the same name. The value of each named argument must be a list, which becomes the values under that column. Naturally, all provided lists must have the same length.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n)\n</code></pre> <p>Note</p> <p>If you poke around in the code, you may notice that the contructor also takes positional arguments. Those are part of the private constructor; don't use them.</p>"},{"location":"creation/#dataframefrom_dict","title":"<code>DataFrame.from_dict</code>","text":"<p>This is basically the same as the constructor, except the arguments are kept as a single dictionary instead of being splatted out. The values of the dictionary can be any <code>Sequence</code>.</p> <pre><code>from tabeline import DataFrame\n\ndata = {\n    \"name\": [\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    \"episode\": [4, 5, 6],\n    \"release_year\": [1977, 1980, 1983],\n}\n\ndf = DataFrame.from_dict(data)\n</code></pre> <p>See also <code>DataFrame.to_dict</code>.</p>"},{"location":"creation/#dataframeread_csv","title":"<code>DataFrame.read_csv</code>","text":"<p>Reads a data frame from a CSV file.</p> <pre><code>from pathlib import Path\nfrom tabeline import DataFrame\n\ndf = DataFrame.read_csv(Path(\"star_wars.csv\"))\n</code></pre> <p>See also <code>DataFrame.write_csv</code>.</p>"},{"location":"creation/#dataframefrom_pandas","title":"<code>DataFrame.from_pandas</code>","text":"<p>Create a <code>tabeline.DataFrame</code> from a <code>pandas.DataFrame</code>. This ignores the index. Use <code>df.reset_index()</code> on the Pandas <code>DataFrame</code> to copy the index to columns first. This requires that the <code>pandas</code> extra is installed (i.e. <code>pip install tabeline[pandas]</code>) because this conversion through Polars relies on PyArrow, which may not otherwise be installed.</p> <pre><code>import pandas as pd\nfrom tabeline import DataFrame\n\npandas_df = pd.DataFrame(dict(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n))\n\ndf = DataFrame.from_pandas(pandas_df)\n</code></pre> <p>See also <code>DataFrame.to_pandas</code>.</p>"},{"location":"creation/#dataframefrom_polars","title":"<code>DataFrame.from_polars</code>","text":"<p>Create a <code>tabeline.DataFrame</code> from a <code>polars.DataFrame</code>. Because Tabeline uses Polars internally, this is a simple wrapper.</p> <pre><code>import polars as pl\nfrom tabeline import DataFrame\n\npolars_df = pl.DataFrame(dict(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n))\n\ndf = DataFrame.from_polars(polars_df)\n</code></pre> <p>See also <code>DataFrame.to_polars</code>.</p>"},{"location":"export/","title":"Export","text":"<p><code>DataFrame</code>s can be converted into various other formats. These mostly mirror the creation methods.</p>"},{"location":"export/#to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary of columns. Each key of the dictionary is a column name, and each value is an <code>Array</code> of the column's values.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n)\n\ndf.to_dict()\n# {\n#     'name': Array(['A New Hope', 'The Empire Strikes Back', 'Return of the Jedi']),\n#     'episode': Arry([4, 5, 6]),\n#     'release_year': Array([1977, 1980, 1983]),\n# }\n</code></pre> <p>See also <code>DataFrame.from_dict</code>.</p>"},{"location":"export/#write_csvfilename","title":"<code>write_csv(filename)</code>","text":"<p>Write to a CSV file. Each column name is a header, and each row is a row of values.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n)\n\ndf.write_csv(\"star_wars.csv\")\n</code></pre> <p>See also <code>DataFrame.read_csv</code>.</p>"},{"location":"export/#to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert to a Pandas <code>DataFrame</code>. This requires that the <code>pandas</code> extra is installed (i.e. <code>pip install tabeline[pandas]</code>).</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n)\n\ndf.to_pandas()\n#                       name  episode  release_year\n# 0               A New Hope        4          1977\n# 1  The Empire Strikes Back        5          1980\n# 2       Return of the Jedi        6          1983\n</code></pre> <p>See also <code>DataFrame.from_pandas</code>.</p>"},{"location":"export/#to_polars","title":"<code>to_polars()</code>","text":"<p>Convert to a Polars <code>DataFrame</code>.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"],\n    episode=[4, 5, 6],\n    release_year=[1977, 1980, 1983],\n)\n\ndf.to_polars()\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 name                    \u2506 episode \u2506 release_year \u2502\n# \u2502 ---                     \u2506 ---     \u2506 ---          \u2502\n# \u2502 str                     \u2506 i64     \u2506 i64          \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 A New Hope              \u2506 4       \u2506 1977         \u2502\n# \u2502 The Empire Strikes Back \u2506 5       \u2506 1980         \u2502\n# \u2502 Return of the Jedi      \u2506 6       \u2506 1983         \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>See also <code>DataFrame.from_polars</code>.</p>"},{"location":"indexing/","title":"Indexing","text":"<p>Indexing is the use of the <code>df[..., ...]</code> syntax to extract values from the data frame. Two arguments are always required, the row index followed by the column index. The returned type depends on which arguments are scalars or slices. This operator ignores any group levels that may be present.</p>"},{"location":"indexing/#dfrow_index-int-column_index-str","title":"<code>df[row_index: int, column_index: str]</code>","text":"<p>Indexing with a scalar row index and a scalar column index returns a scalar value. The returned type is a Python type, <code>bool</code>, <code>int</code>, <code>float</code>, or <code>str</code>.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    book=[\"The Hobbit\", \"The Fellowship of the Ring\", \"The Two Towers\", \"The Return of the King\"],\n    year=[1937, 1954, 1954, 1955],\n    word_count=[95356, 187790, 156198, 137115],\n)\n\nassert df[2, \"book\"] == \"The Two Towers\"\n</code></pre>"},{"location":"indexing/#dfrow_index-int-column_index-slice-sequencestr","title":"<code>df[row_index: int, column_index: slice | Sequence[str]]</code>","text":"<p>If only the row index is a scalar, indexing returns a <code>tabeline.Record</code>. Functionally, a <code>Record</code> is an ordered dict.</p> <p>A <code>Record</code> can be iterated over or indexed further. Each key is a string, and each value is a Python type, <code>bool</code>, <code>int</code>, <code>float</code>, <code>str</code>, or <code>None</code>. The underlying data types are lost when a <code>Record</code> is created.</p> <p>A <code>slice(None)</code> (i.e. <code>:</code>, all columns) is the only slice allowed. Sliced <code>str</code> ranges are not supported. To select a subset of columns, list them as a sequence of strings.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    book=[\"The Hobbit\", \"The Fellowship of the Ring\", \"The Two Towers\", \"The Return of the King\"],\n    year=[1937, 1954, 1954, 1955],\n    word_count=[95356, 187790, 156198, 137115],\n)\n\nassert df[2, :] == Record(book=\"The Two Towers\", year=1954, word_count=156198)\nassert df[2, :][\"book\"] == \"The Two Towers\"\n</code></pre>"},{"location":"indexing/#dfrow_index-slice-sequenceint-column_index-str","title":"<code>df[row_index: slice | Sequence[int], column_index: str]</code>","text":"<p>If only the column index is a scalar, indexing returns a <code>tabeline.Array</code>. Functionally, an <code>Array</code> is a list.</p> <p>Normal <code>slice</code>s are permitted on the row index and behave as expected. Selecting specific rows with a sequennce of integers is also allowed.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    book=[\"The Hobbit\", \"The Fellowship of the Ring\", \"The Two Towers\", \"The Return of the King\"],\n    year=[1937, 1954, 1954, 1955],\n    word_count=[95356, 187790, 156198, 137115],\n)\n\nassert df[:, \"word_count\"] == Array(95356, 187790, 156198, 137115)\nassert df[:, \"word_count\"][2] == 156198\n</code></pre>"},{"location":"indexing/#array","title":"<code>Array</code>","text":"<p>Each <code>Array</code> has a given data type that restricts the possible values that the elements may have. The data type can be accessed via the <code>Array.data_type</code> attribute, which returns a member of the <code>tabeline.DataType</code> enum. All the elements in a given <code>Array</code> are instances of that type or are null. Tabeline currently has no scalar values so getting a lone instance of the data type in Python is not possible. Extracting a single element from an <code>Array</code> or <code>DataFrame</code> returns an object with one of these basic Python types: <code>bool</code>, <code>int</code>, <code>float</code>, <code>str</code>, or <code>None</code>.</p> <p>The possible data types are listed below. The <code>in</code> column in the table below indicate which Python type is converted to that data type. The <code>out</code> column indicates with Python type is returned when extracting a value from that data type.</p> DataType in out Boolean bool bool Integer8 int Integer16 int Integer32 int Integer64 int int Whole8 int Whole16 int Whole32 int Whole64 int Float32 float Float64 float float String str str Nothing"},{"location":"indexing/#dfrow_index-slice-sequenceint-column_index-slice-sequencestr","title":"<code>df[row_index: slice | Sequence[int], column_index: slice | Sequence[str]]</code>","text":"<p>Slicing both the row index and the column index returns another <code>tabeline.DataFrame</code>.</p> <p>The resulting <code>DataFrame</code> has no group levels regardless of the parent.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    book=[\"The Hobbit\", \"The Fellowship of the Ring\", \"The Two Towers\", \"The Return of the King\"],\n    year=[1937, 1954, 1954, 1955],\n    word_count=[95356, 187790, 156198, 137115],\n)\n\nassert df[1:3, [\"book\", \"year\"]] == DataFrame(\n    book=[\"The Fellowship of the Ring\", \"The Two Towers\"],\n    year=[1954, 1954],\n)\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>This is an index of the main functionality available in Tabeline. Each constructor and verb has a link to more detailed documentation. The expression functions do not yet have detailed documentation, but should be self-explanatory.</p>"},{"location":"overview/#creation","title":"Creation","text":"<p>These are the ways to create a <code>DataFrame</code> from something that is not already a <code>DataFrame</code></p> <ul> <li><code>DataFrame(**columns)</code>: Construct data frame directly from columns</li> <li><code>DataFrame.from_dict(columns)</code>: Construct data frame directly from columns</li> <li><code>DataFrame.read_csv(filename)</code>: Read data frame from CSV file</li> <li><code>DataFrame.from_pandas(df)</code>: Convert from Pandas <code>DataFrame</code></li> <li><code>DataFrame.from_polars(df)</code>: Convert from Polars <code>DataFrame</code></li> </ul>"},{"location":"overview/#export","title":"Export","text":"<p>These are the various things that a <code>DataFrame</code> can be converted into</p> <ul> <li><code>to_dict()</code>: Convert to dictionary of columns</li> <li><code>to_pandas()</code>: Convert to Pandas <code>DataFrame</code></li> <li><code>to_polars()</code>: Convert to Polars <code>DataFrame</code></li> <li><code>write_csv(filename)</code>: Write to CSV file</li> </ul>"},{"location":"overview/#verbs","title":"Verbs","text":"<p>Each verb is a method of <code>DataFrame</code>.</p>"},{"location":"overview/#column-reorganization","title":"Column reorganization","text":"<ul> <li><code>select</code>: Keep given columns</li> <li><code>deselect</code>: Drop given columns</li> <li><code>rename</code>: Rename columns</li> </ul>"},{"location":"overview/#row-removal","title":"Row removal","text":"<ul> <li><code>filter</code>: Keep rows for which predicate is true</li> <li><code>slice0</code>: Keep rows given by 0-index</li> <li><code>slice1</code>: Keep rows given by 1-index</li> <li><code>distinct</code>: Drop rows with duplicate values under given columns</li> <li><code>unique</code>: Drop rows with duplicate values under all columns</li> </ul>"},{"location":"overview/#row-reordering","title":"Row reordering","text":"<ul> <li><code>sort</code>: Sort data frame according to given columns</li> <li><code>cluster</code>: Bring rows together with same values under given columns</li> </ul>"},{"location":"overview/#column-mutation","title":"Column mutation","text":"<ul> <li><code>mutate</code>: Create or update columns according to given expressions</li> <li><code>transmute</code>: Mutate while dropping existing columns</li> </ul>"},{"location":"overview/#grouping","title":"Grouping","text":"<ul> <li><code>group_by</code>: Create a group level containing given columns</li> <li><code>ungroup</code>: Drop the last group level</li> </ul>"},{"location":"overview/#summarizing","title":"Summarizing","text":"<ul> <li><code>summarize</code>: Reduce each group to a single row according to given expressions</li> </ul>"},{"location":"overview/#reshaping","title":"Reshaping","text":"<ul> <li><code>spread</code>: Reshape from long format to wide format</li> <li><code>gather</code>: Reshape from wide format to long format</li> </ul>"},{"location":"overview/#joining","title":"Joining","text":"<ul> <li><code>inner_join</code>: Merge data frames, dropping unmatched</li> <li><code>outer_join</code>: Merge data frames, adding nulls for unmatched</li> <li><code>left_join</code>: Merge data frames, adding nulls for unmatched on the left data frame</li> </ul>"},{"location":"overview/#concatenating","title":"Concatenating","text":"<ul> <li><code>concatenate_rows</code>: Concatenate rows of data frames</li> <li><code>concatenate_columns</code>: Concatenate columns of data frames</li> </ul>"},{"location":"overview/#functions","title":"Functions","text":"<p>These are the operators and functions available in the string expressions.</p>"},{"location":"overview/#operators","title":"Operators","text":"<p>If either operand is null, the result is null.</p> <ul> <li><code>x + y</code>: <code>x</code> plus <code>y</code> or, if strings, <code>x</code> concatenated to <code>y</code></li> <li><code>x - y</code>: <code>x</code> minus <code>y</code></li> <li><code>x * y</code>: <code>x</code> times <code>y</code></li> <li><code>x / y</code>: <code>x</code> divided by <code>y</code></li> <li><code>x % y</code>: <code>x</code> mod <code>y</code></li> <li><code>x ** y</code>: <code>x</code> to the power of <code>y</code></li> </ul>"},{"location":"overview/#numeric-to-numeric-broadcast","title":"Numeric to numeric broadcast","text":"<p>The functions in this section mathematical operations on numbers. If these functions receive scalar inputs, they return a scalar. If they receive any array inputs, any scalars are interpreted as constant vectors and an array is returned. For each null element, the result is null.</p> <ul> <li><code>abs(x)</code>: Absolute value of <code>x</code></li> <li><code>sqrt(x)</code>: Square root of <code>x</code></li> <li><code>log(x)</code>: Natural logarithm of <code>x</code></li> <li><code>log2(x)</code>: Base-2 logarithm of <code>x</code></li> <li><code>log10(x)</code>: Base-10 logarithm of <code>x</code></li> <li><code>exp(x)</code>: Euler's number <code>e</code> to the power of <code>x</code></li> <li><code>pow(x, y)</code>: <code>x</code> to the power of <code>y</code></li> <li><code>sin(x)</code>: Sine of <code>x</code></li> <li><code>cos(x)</code>: Cosine of <code>x</code></li> <li><code>tan(x)</code>: Tangent of <code>x</code></li> <li><code>arcsin(x)</code>: Inverse sine of <code>x</code></li> <li><code>arccos(x)</code>: Inverse cosine of <code>x</code></li> <li><code>arctan(x)</code>: Inverse tangent of <code>x</code></li> <li><code>floor(x)</code>: <code>x</code> rounded down to the nearest integer</li> <li><code>ceil(x)</code>: <code>x</code> rounded up to the nearest integer</li> </ul>"},{"location":"overview/#numeric-to-boolean-broadcast","title":"Numeric to boolean broadcast","text":"<p>For each null element, the result is null.</p> <ul> <li><code>is_nan(x)</code>: True if <code>x</code> value is a floating point <code>NaN</code></li> <li><code>is_finite(x)</code>: True if <code>x</code> value is a floating point finite number</li> </ul>"},{"location":"overview/#casting-broadcast","title":"Casting broadcast","text":"<p>The functions in this section convert values from one type to another. These are completely dependent on the behavior of the Polars <code>cast</code> function. Nulls are preserved.</p> <ul> <li><code>to_boolean(x)</code>: Convert <code>x</code> from a boolean, a float, or an integer, to a boolean</li> <li><code>to_integer(x)</code>: Convert <code>x</code> from a boolean, a float, or an integer to an integer or parse a string as an integer</li> <li><code>to_float(x)</code>: Convert <code>x</code> from a boolean, a float, or an integer to a float or parse a string as a float</li> <li><code>to_string(x)</code>: Deparse <code>x</code> to a string</li> </ul>"},{"location":"overview/#other-broadcast","title":"Other broadcast","text":"<ul> <li><code>is_null(x)</code>: True if <code>x</code> is null. This is one of the few functions that returns a non-null value on null inputs.</li> <li><code>if_else(condition, true_value, false_value)</code>: If <code>condition</code> is true, return <code>true_value</code>, otherwise return <code>false_value</code>.</li> </ul>"},{"location":"overview/#numeric-to-numeric-reduction","title":"Numeric to numeric reduction","text":"<p>The functions in this section consume an entire column of numbers and to produce a scalar number. If any element is null, the result is null.</p> <ul> <li><code>std(x)</code>: Population standard deviation of <code>x</code></li> <li><code>var(x)</code>: Population variance of <code>x</code></li> <li><code>max(x)</code>: Maximum of <code>x</code></li> <li><code>min(x)</code>: Minimum of <code>x</code></li> <li><code>sum(x)</code>: Sum of <code>x</code></li> <li><code>mean(x)</code>: Mean of <code>x</code></li> <li><code>median(x)</code>: Median of <code>x</code></li> <li><code>quantile(x, quantile)</code>: The <code>quantile</code> of <code>x</code> obtained via linear interpolation</li> <li><code>quantile</code> must be a <code>float</code> literal not an expression</li> <li><code>trapz(x, y)</code>: Numerically integrate <code>y</code> over <code>x</code> using the trapezoidal rule</li> <li><code>interp(x, xp, fp)</code>: Linearly interpolate <code>fp</code> over <code>xp</code> at <code>x</code>; typically, <code>x</code> is a float literal</li> </ul>"},{"location":"overview/#boolean-to-boolean-reduction","title":"Boolean to boolean reduction","text":"<p>The functions in this section consume an entire column of booleans and to produce a scalar boolean. These follow Kleene logic with respect to null.</p> <ul> <li><code>any(x)</code>: True if any of <code>x</code> are true</li> <li><code>all(x)</code>: True is all of <code>x</code> are true</li> </ul>"},{"location":"overview/#any-to-any-reduction","title":"Any to any reduction","text":"<p>The functions in this section consume an entire column of anything and to produce a scalar of that type. These treat nulls as normal values.</p> <ul> <li><code>first(x)</code>: The first value of <code>x</code></li> <li><code>last(x)</code>: The last value of <code>x</code></li> <li><code>same(x)</code>: One value of <code>x</code> if all values of <code>x</code> are the same, otherwise error</li> </ul>"},{"location":"overview/#argumentless-functions","title":"Argumentless functions","text":"<p>The functions in this section evalute in the context of the <code>DataFrame</code>, not any particular column.</p> <ul> <li><code>n()</code>: The number of rows in the <code>DataFrame</code></li> <li><code>row_index0()</code>: The 0-index of each row</li> <li><code>row_index1()</code>: The 1-index of each row</li> </ul>"},{"location":"verbs/concatenate/","title":"Concatenating multiple data frames","text":"<p>The <code>concatenate_rows</code> and <code>concatenate_columns</code> functions are not really verbs in the data grammar, but are more like conjunctions. They are the only operations that take an arbitrary number of data frames as arguments. As such, they are genuine Python functions importable from <code>tabeline</code>, not methods of <code>DataFrame</code>.</p>"},{"location":"verbs/concatenate/#concatenate_rows","title":"<code>concatenate_rows</code>","text":"<p>Concatenate the rows of the given data frames into a single data frame. The data frames must have the same columns, in the same order. Typically, only data frames without grouping are concatenated, but concatenation will be allowed if all group levels are identical. In other libraries, this operation may be called \"row binding\" or \"vertical stacking\".</p> <pre><code>from tabeline import DataFrame, concatenate_rows\n\nstudy1 = DataFrame(study=[1, 1, 1], subject=[10, 11, 12])\nstudy2 = DataFrame(study=[2, 2, 2], subject=[20, 21, 22])\n\nconcatenate_rows(study1, study2)\n# shape: (6, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 study \u2506 subject \u2502\n# \u2502 ---   \u2506 ---     \u2502\n# \u2502 i64   \u2506 i64     \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1     \u2506 10      \u2502\n# \u2502 1     \u2506 11      \u2502\n# \u2502 1     \u2506 12      \u2502\n# \u2502 2     \u2506 20      \u2502\n# \u2502 2     \u2506 21      \u2502\n# \u2502 2     \u2506 22      \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/concatenate/#concatenate_columns","title":"<code>concatenate_columns</code>","text":"<p>Concatenate the columns of the given data frames into a single data frame. All data frames must have the same number of rows. No columns may be duplicated. No group levels may be present. In other libraries, this operation may be called \"column binding\" or \"horizontal stacking\".</p> <p>This is one of the most dangerous operations in Tabeline. Often, <code>inner_join</code> is a safer choice than <code>concatenate_columns</code>. Joining on key columns ensures that the data is correctly matched even if the row order is mixed up.</p> <pre><code>from tabeline import DataFrame, concatenate_columns\n\nstudy1 = DataFrame(study=[1, 1, 1], subject=[10, 10, 11])\nstudy2 = DataFrame(measurements=[12.5, 12.0, 5.6])\n\nconcatenate_columns(study1, study2)\n# shape: (3, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 study \u2506 subject \u2506 measurements \u2502\n# \u2502 ---   \u2506 ---     \u2506 ---          \u2502\n# \u2502 i64   \u2506 i64     \u2506 f64          \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1     \u2506 10      \u2506 12.5         \u2502\n# \u2502 1     \u2506 10      \u2506 12.0         \u2502\n# \u2502 1     \u2506 11      \u2506 5.6          \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/filter/","title":"Row dropping","text":"<p>The <code>filter</code>, <code>slice0</code>, <code>slice1</code>, <code>distinct</code>, and <code>unique</code> verbs change which rows are present. The relative order of the rows is unchanged.</p>"},{"location":"verbs/filter/#filter","title":"<code>filter</code>","text":"<p>Keep the rows for which a given predicate evaluates to true. <code>filter</code> takes a single expression, which in the context of the data frame, must evaluate to a boolean column. All rows with a corresponding false value are dropped.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"Alice\", \"Bob\", \"Carole\", \"Mallory\"],\n    age=[28, 55, 55, 18],\n)\n\ndf.filter(\"age == max(age)\")\n# shape: (2, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 name   \u2506 age \u2502\n# \u2502 ---    \u2506 --- \u2502\n# \u2502 str    \u2506 i64 \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 Bob    \u2506 55  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 Carole \u2506 55  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/filter/#slice0","title":"<code>slice0</code>","text":"<p>Keep only the rows whose 0-based index is listed, and in the order listed.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    id=[1, 2, 3, 4],\n    character=[\"a\", \"b\", \"c\", \"d\"],\n)\n\ndf.slice0([2, 1])\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 character \u2502\n# \u2502 --- \u2506 ---       \u2502\n# \u2502 i64 \u2506 str       \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 3   \u2506 c         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2   \u2506 b         \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/filter/#slice1","title":"<code>slice1</code>","text":"<p>Keep only the rows whose 1-based index is listed, and in the order listed. This is identical to <code>slice0</code> except for the interpretation of the index.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    id=[1, 2, 3, 4],\n    character=[\"a\", \"b\", \"c\", \"d\"],\n)\n\ndf.slice1([2, 1])\n# shape: (2, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 character \u2502\n# \u2502 --- \u2506 ---       \u2502\n# \u2502 i64 \u2506 str       \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 2   \u2506 b         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1   \u2506 a         \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/filter/#distinct","title":"<code>distinct</code>","text":"<p>Keep the first row for each unique record in the columns whose names are listed.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    given_name=[\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\"],\n    family_name=[\"Smith\", \"Smith\", \"Smith\", \"Jones\", \"Smith\"],\n    age=[28, 30, 30, 18, 30],\n)\n\ndf.distinct(\"given_name\", \"family_name\")\n# shape: (3, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 given_name \u2506 family_name \u2506 age \u2502\n# \u2502 ---        \u2506 ---         \u2506 --- \u2502\n# \u2502 str        \u2506 str         \u2506 i64 \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 Alice      \u2506 Smith       \u2506 28  \u2502\n# \u2502 Bob        \u2506 Smith       \u2506 30  \u2502\n# \u2502 Alice      \u2506 Jones       \u2506 18  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/filter/#unique","title":"<code>unique</code>","text":"<p>Keep the first row of each unique record. This is equivalent to <code>distinct</code> with all columns.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    given_name=[\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\"],\n    family_name=[\"Smith\", \"Smith\", \"Smith\", \"Jones\", \"Smith\"],\n    age=[28, 30, 30, 18, 30],\n)\n\ndf.unique()\n# shape: (4, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 given_name \u2506 family_name \u2506 age \u2502\n# \u2502 ---        \u2506 ---         \u2506 --- \u2502\n# \u2502 str        \u2506 str         \u2506 i64 \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 Alice      \u2506 Smith       \u2506 28  \u2502\n# \u2502 Bob        \u2506 Smith       \u2506 30  \u2502\n# \u2502 Alice      \u2506 Smith       \u2506 30  \u2502\n# \u2502 Alice      \u2506 Jones       \u2506 18  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/group_by/","title":"Changing group levels","text":"<p><code>group_by</code> is not so much a verb as it is a preposition. <code>group_by</code> does not change the contents or orders of any rows or columns, but it changes the context of subsequent verbs. All rows which have the same values in all <code>group_by</code> columns are members of the same subframe. Subsequent verbs act as if they are applied each subframe individually. So in <code>filter</code> or <code>mutate</code>, an expression containing <code>max</code> or <code>mean</code> will apply only to the rows in each subframe.</p> <p>Tabeline is different from all popular data grammar libraries in how it handles groups. An instance of <code>DataFrame</code> has group levels. Each invocation of <code>group_by</code> adds one group level, which can contain any number of columns names by which to group. The flattened list of group names from all levels can be accessed via the <code>group_names</code> property.</p>"},{"location":"verbs/group_by/#group_by","title":"<code>group_by</code>","text":"<p>Add a set of column names as a new group level. The column names must exist, and they must not be previously grouped.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    id=[\"a\", \"a\", \"b\", \"b\"],\n    x=[1, 2, 3, 4],\n)\n\ndf.group_by(\"id\").mutate(mean=\"mean(x)\")\n# group levels: [id]\n# shape: (4, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 x   \u2506 mean \u2502\n# \u2502 --- \u2506 --- \u2506 ---  \u2502\n# \u2502 str \u2506 i64 \u2506 f64  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 a   \u2506 1   \u2506 1.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 a   \u2506 2   \u2506 1.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 b   \u2506 3   \u2506 3.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 b   \u2506 4   \u2506 3.5  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/group_by/#ungroup","title":"<code>ungroup</code>","text":"<p>Drop the last group level.</p> <p>The existence of group levels causes this to behave differently from dplyr. This does not remove all group names, only those present in the last group level.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    id=[\"a\", \"a\", \"b\", \"b\"],\n    x=[1, 2, 3, 4],\n)\n\ndf.group_by(\"id\").mutate(mean=\"mean(x)\")\n# shape: (4, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 x   \u2506 mean \u2502\n# \u2502 --- \u2506 --- \u2506 ---  \u2502\n# \u2502 str \u2506 i64 \u2506 f64  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 a   \u2506 1   \u2506 2.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 a   \u2506 2   \u2506 2.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 b   \u2506 3   \u2506 2.5  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 b   \u2506 4   \u2506 2.5  \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/join/","title":"Joining two data frames","text":"<p>The <code>inner_join</code>, <code>outer_join</code>,  and <code>left_join</code> verbs perform the classic table join operations.</p>"},{"location":"verbs/join/#inner_join","title":"<code>inner_join</code>","text":"<p>This method performs the classic inner join operation. Rows on either side that are missing a corresponding row on the other side are dropped. Rows on either side that have multiple matches on the other side are duplicated.</p> <pre><code>from tabeline import DataFrame\n\ndf1 = DataFrame(x=[0, 1, 2, 3, 4], y=[\"a\", \"b\", \"c\", \"d\", \"e\"])\ndf2 = DataFrame(x=[3, 2, -1, 1, 0], z=[\"a\", \"b\", \"z\", \"c\", \"d\"])\n\ndf1.inner_join(df2)\n# shape: (4, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 x   \u2506 y   \u2506 z   \u2502\n# \u2502 --- \u2506 --- \u2506 --- \u2502\n# \u2502 i64 \u2506 str \u2506 str \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 0   \u2506 a   \u2506 d   \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1   \u2506 b   \u2506 c   \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2   \u2506 c   \u2506 b   \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 3   \u2506 d   \u2506 a   \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/join/#outer_join","title":"<code>outer_join</code>","text":"<p>This method performs the classic outer join (or full join) operation. Rows on either side that are missing a corresponding row on the other side are kept, filling the other side with nulls. Rows on either side that have multiple matches on the other side are duplicated.</p> <pre><code>from tabeline import DataFrame\n\ndf1 = DataFrame(x=[0, 1, 2, 3, 4], y=[\"a\", \"b\", \"c\", \"d\", \"e\"])\ndf2 = DataFrame(x=[3, 2, -1, 1, 0], z=[\"a\", \"b\", \"z\", \"c\", \"d\"])\n\ndf1.outer_join(df2)\n# shape: (6, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 x   \u2506 y    \u2506 z    \u2502\n# \u2502 --- \u2506 ---  \u2506 ---  \u2502\n# \u2502 i64 \u2506 str  \u2506 str  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 -1  \u2506 null \u2506 z    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 0   \u2506 a    \u2506 d    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1   \u2506 b    \u2506 c    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2   \u2506 c    \u2506 b    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 3   \u2506 d    \u2506 a    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 4   \u2506 e    \u2506 null \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/join/#left_join","title":"<code>left_join</code>","text":"<p>This method performs the classic left join operation. Rows on the left side that are missing a corresponding row on the right side are kept, filling the right side with nulls. Rows on the right side that are missing a corresponding row on the left side are dropped. Rows on either side that have multiple matches on the other side are duplicated.</p> <pre><code>from tabeline import DataFrame\n\ndf1 = DataFrame(x=[0, 1, 2, 3, 4], y=[\"a\", \"b\", \"c\", \"d\", \"e\"])\ndf2 = DataFrame(x=[3, 2, -1, 1, 0], z=[\"a\", \"b\", \"z\", \"c\", \"d\"])\n\ndf1.left_join(df2)\n# shape: (5, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 x   \u2506 y   \u2506 z    \u2502\n# \u2502 --- \u2506 --- \u2506 ---  \u2502\n# \u2502 i64 \u2506 str \u2506 str  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 0   \u2506 a   \u2506 d    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1   \u2506 b   \u2506 c    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2   \u2506 c   \u2506 b    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 3   \u2506 d   \u2506 a    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 4   \u2506 e   \u2506 null \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/mutate/","title":"Creating new columns","text":"<p>The <code>mutate</code> and <code>transmute</code> verbs create new columns based on expressions of existing columns. The number of rows is unchanged.</p>"},{"location":"verbs/mutate/#mutate","title":"<code>mutate</code>","text":"<p>Create new columns or redefine existing columns. This takes an arbitrary number of named arguments. The name of each argument is the name of a column. The value of the argument is an expression that provides a definition for that column. If the column name already exists, that column will be replaced by the evaluation of the new definition. If the column name does not already exist, the new column will be appended to the existing columns.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"wide\", \"tall\", \"square\"],\n    width=[5, 2, 3],\n    height=[1, 4, 3],\n)\n\ndf.mutate(area=\"width * height\")\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 name   \u2506 width \u2506 height \u2506 area \u2502\n# \u2502 ---    \u2506 ---   \u2506 ---    \u2506 ---  \u2502\n# \u2502 str    \u2506 i64   \u2506 i64    \u2506 i64  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 wide   \u2506 5     \u2506 1      \u2506 5    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 tall   \u2506 2     \u2506 4      \u2506 8    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 square \u2506 3     \u2506 3      \u2506 9    \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/mutate/#transmute","title":"<code>transmute</code>","text":"<p>Just like mutate except the existing columns are not kept. This is identical to <code>mutate</code> followed by <code>select</code> on the newly defined columns.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[\"wide\", \"tall\", \"square\"],\n    width=[5, 2, 3],\n    height=[1, 4, 3],\n)\n\ndf.transmute(name=\"name\", area=\"width * height\")\n# shape: (3, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 name   \u2506 area \u2502\n# \u2502 ---    \u2506 ---  \u2502\n# \u2502 str    \u2506 i64  \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 wide   \u2506 5    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 tall   \u2506 8    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 square \u2506 9    \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/select/","title":"Column dropping and reordering","text":"<p>The <code>select</code>, <code>deselect</code>, and <code>rename</code> verbs change which columns are present in the data frame, their order, and what names they have. The content of the columns is unchanged.</p>"},{"location":"verbs/select/#select","title":"<code>select</code>","text":"<p>Keep only the columns whose names are listed, in the order they are listed.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    study=[1, 2],\n    location=[\"USA\", \"USA\"],\n    cost=[3254, 11843],\n    success=[True, False],\n)\n\ndf.select(\"study\", \"success\", \"cost\")\n# shape: (2, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 study \u2506 success \u2506 cost  \u2502\n# \u2502 ---   \u2506 ---     \u2506 ---   \u2502\n# \u2502 i64   \u2506 bool    \u2506 i64   \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1     \u2506 true    \u2506 3254  \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2     \u2506 false   \u2506 11843 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/select/#deselect","title":"<code>deselect</code>","text":"<p>Drop the columns whose names are listed.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    study=[1, 2],\n    location=[\"USA\", \"USA\"],\n    cost=[3254, 11843],\n    success=[True, False],\n)\n\ndf.deselect(\"location\")\n# shape: (2, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 study \u2506 cost  \u2506 success \u2502\n# \u2502 ---   \u2506 ---   \u2506 ---     \u2502\n# \u2502 i64   \u2506 i64   \u2506 bool    \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1     \u2506 3254  \u2506 true    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2     \u2506 11843 \u2506 false   \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/select/#rename","title":"<code>rename</code>","text":"<p>Change the name of some columns, keeping their original order unchanged. This takes named arguments, where the key is the new name and the value is the old name. In this, Tabeline is like dyplr rename rather than Polars rename, which flips the order of the new and old names.</p> <p>The renaming happens simultaneously, allowing column names to be swapped.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    name=[1, 2],\n    full_name=[\"Alice\", \"Bob\"],\n    age=[27, 55],\n    authorized=[True, True],\n)\n\ndf.rename(name=\"full_name\", id=\"name\")\n# shape: (2, 4)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 name  \u2506 age \u2506 authorized \u2502\n# \u2502 --- \u2506 ---   \u2506 --- \u2506 ---        \u2502\n# \u2502 i64 \u2506 str   \u2506 i64 \u2506 bool       \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1   \u2506 Alice \u2506 27  \u2506 true       \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2   \u2506 Bob   \u2506 55  \u2506 true       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/sort/","title":"Row reordering","text":"<p>The <code>sort</code> and <code>cluster</code> verbs change the order of rows. The individual rows are unchanged.</p>"},{"location":"verbs/sort/#sort","title":"<code>sort</code>","text":"<p>Sort rows according to the given column names. The data frame is sorted by the first column name using subsequent columns to break any ties.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    patient_id=[2, 1, 2, 1, 2, 1],\n    t=[0.0, 0.0, 6.0, 6.0, 24.0, 24.0],\n    measurement=[6.0, 5.5, 4.2, 4.0, 3.1, 3.0],\n)\n\ndf.sort(\"patient_id\", \"t\")\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 patient_id \u2506 t    \u2506 measurement \u2502\n# \u2502 ---        \u2506 ---  \u2506 ---         \u2502\n# \u2502 i64        \u2506 f64  \u2506 f64         \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 1          \u2506 0.0  \u2506 5.5         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1          \u2506 6.0  \u2506 4.0         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1          \u2506 24.0 \u2506 3.0         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2          \u2506 0.0  \u2506 6.0         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2          \u2506 6.0  \u2506 4.2         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2          \u2506 24.0 \u2506 3.1         \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/sort/#cluster","title":"<code>cluster</code>","text":"<p>Bring together all the rows with the same value under the given columns. A side effect of <code>sort</code> is that all rows with the same key value under some given columns are brought together. If you want this clustering, without the sorting, <code>cluster</code> will bring all the rows with a given key together, but retain the order of first instance of that key.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    patient_id=[2, 1, 2, 1, 2, 1],\n    t=[0.0, 0.0, 6.0, 6.0, 24.0, 24.0],\n    measurement=[6.0, 5.5, 4.2, 4.0, 3.1, 3.0],\n)\n\ndf.cluster(\"patient_id\")\nshape: (6, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 patient_id \u2506 t    \u2506 measurement \u2502\n# \u2502 ---        \u2506 ---  \u2506 ---         \u2502\n# \u2502 i64        \u2506 f64  \u2506 f64         \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 2          \u2506 0.0  \u2506 6.0         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2          \u2506 6.0  \u2506 4.2         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 2          \u2506 24.0 \u2506 3.1         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1          \u2506 0.0  \u2506 5.5         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1          \u2506 6.0  \u2506 4.0         \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 1          \u2506 24.0 \u2506 3.0         \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/spread/","title":"Pivoting between wide and tall formats","text":"<p>The <code>spread</code> and <code>gather</code> verbs reshape a data frame between long format and wide format of data representation.</p>"},{"location":"verbs/spread/#spread","title":"<code>spread</code>","text":"<p>Turn a long data frame into a wide data frame. This operation takes the names of two columns, a key column and a value column. Every value in the key column becomes a column name and every value in the value column becomes a value under its respective column.</p> <p><code>spread</code> is a reduction verb. As such, it drops the last group level, and it cannot be applied to data frames with no group levels.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    grades=[0, 0, 1, 1, 2, 2],\n    sex=[\"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n    count=[8, 9, 9, 10, 6, 9],\n)\n\ndf.group_by(\"sex\").spread(\"grades\", \"count\")\n# shape: (2, 4)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 sex \u2506 0   \u2506 1   \u2506 2   \u2502\n# \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2502\n# \u2502 str \u2506 i64 \u2506 i64 \u2506 i64 \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 M   \u2506 8   \u2506 9   \u2506 6   \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 F   \u2506 9   \u2506 10  \u2506 9   \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/spread/#gather","title":"<code>gather</code>","text":"<p>Turn a wide data frame into a long data frame. This operation takes the name of a key column that not exist, the name of a value column that does not exist, and an arbitrary number of existing column names. Each value under the existing columns is converted to a value under the new value column, with the name of the column put next to it under the key column.</p> <p><code>gather</code> adds one group level containing the key column name.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame.from_dict({\n    \"sex\": [\"M\", \"F\"],\n    \"0\": [8, 9],\n    \"1\": [9, 10],\n    \"2\": [6, 9]},\n)\n\ndf.gather(\"grades\", \"count\", \"0\", \"1\", \"2\")\n# group levels: [grades]\n# shape: (6, 3)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 sex \u2506 grades \u2506 count \u2502\n# \u2502 --- \u2506 ---    \u2506 ---   \u2502\n# \u2502 str \u2506 str    \u2506 i64   \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 M   \u2506 0      \u2506 8     \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 F   \u2506 0      \u2506 9     \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 M   \u2506 1      \u2506 9     \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 F   \u2506 1      \u2506 10    \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 M   \u2506 2      \u2506 6     \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 F   \u2506 2      \u2506 9     \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"verbs/summarize/","title":"Reducing subframes","text":""},{"location":"verbs/summarize/#summarize","title":"<code>summarize</code>","text":"<p>Reduce each subframe to a single row. This operation can only be applied to a data frame with at least one group level. The result has one column for each group column name and one column for each named argument. The name of the argument becomes the column name and the value of the argument must be an expression that evaluates to a scalar. That scalar will be the value of the cell for each summarized subframe. The last group level is dropped.</p> <pre><code>from tabeline import DataFrame\n\ndf = DataFrame(\n    id=[\"a\", \"a\", \"b\", \"b\"],\n    x=[1, 2, 3, 4],\n)\n\ndf.group_by(\"id\").summarize(x=\"mean(x)\")\n# shape: (2, 2)\n# \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 id  \u2506 x   \u2502\n# \u2502 --- \u2506 --- \u2502\n# \u2502 str \u2506 f64 \u2502\n# \u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n# \u2502 a   \u2506 1.5 \u2502\n# \u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u2524\n# \u2502 b   \u2506 3.5 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"}]}